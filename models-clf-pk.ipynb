{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1971405,"sourceType":"datasetVersion","datasetId":1177531}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install streamlit\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T11:07:29.058725Z","iopub.execute_input":"2024-01-13T11:07:29.059473Z","iopub.status.idle":"2024-01-13T11:07:45.461556Z","shell.execute_reply.started":"2024-01-13T11:07:29.059428Z","shell.execute_reply":"2024-01-13T11:07:45.460501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import streamlit as st\nimport pickle\nimport re\nimport nltk\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\n#loading models\nclf = pickle.load(open('clf.pkl','rb'))\ntfidfd = pickle.load(open('tfidf.pkl','rb'))\n\ndef clean_resume(resume_text):\n    clean_text = re.sub('http\\S+\\s*', ' ', resume_text)\n    clean_text = re.sub('RT|cc', ' ', clean_text)\n    clean_text = re.sub('#\\S+', '', clean_text)\n    clean_text = re.sub('@\\S+', '  ', clean_text)\n    clean_text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', clean_text)\n    clean_text = re.sub(r'[^\\x00-\\x7f]', r' ', clean_text)\n    clean_text = re.sub('\\s+', ' ', clean_text)\n    return clean_text\n# web app\ndef main():\n    st.title(\"Resume Screening App\")\n    uploaded_file = st.file_uploader('Upload Resume', type=['txt','pdf'])\n\n    if uploaded_file is not None:\n        try:\n            resume_bytes = uploaded_file.read()\n            resume_text = resume_bytes.decode('utf-8')\n        except UnicodeDecodeError:\n            # If UTF-8 decoding fails, try decoding with 'latin-1'\n            resume_text = resume_bytes.decode('latin-1')\n\n        cleaned_resume = clean_resume(resume_text)\n        input_features = tfidfd.transform([cleaned_resume])\n        prediction_id = clf.predict(input_features)[0]\n        st.write(prediction_id)\n\n        # Map category ID to category name\n        category_mapping = {\n            15: \"Java Developer\",\n            23: \"Testing\",\n            8: \"DevOps Engineer\",\n            20: \"Python Developer\",\n            24: \"Web Designing\",\n            12: \"HR\",\n            13: \"Hadoop\",\n            3: \"Blockchain\",\n            10: \"ETL Developer\",\n            18: \"Operations Manager\",\n            6: \"Data Science\",\n            22: \"Sales\",\n            16: \"Mechanical Engineer\",\n            1: \"Arts\",\n            7: \"Database\",\n            11: \"Electrical Engineering\",\n            14: \"Health and fitness\",\n            19: \"PMO\",\n            4: \"Business Analyst\",\n            9: \"DotNet Developer\",\n            2: \"Automation Testing\",\n            17: \"Network Security Engineer\",\n            21: \"SAP Developer\",\n            5: \"Civil Engineer\",\n            0: \"Advocate\",\n        }\n\n        category_name = category_mapping.get(prediction_id, \"Unknown\")\n\n        st.write(\"Predicted Category:\", category_name)\n\n\n\n# python main\nif __name__ == \"__main__\":\n    main()","metadata":{},"execution_count":null,"outputs":[]}]}